============================================================================
                            REVIEWER #1
============================================================================

---------------------------------------------------------------------------
Reviewer's Scores
---------------------------------------------------------------------------
                   Appropriateness (1-5): 4
                           Clarity (1-5): 2
      Originality / Innovativeness (1-5): 3
           Soundness / Correctness (1-5): 3
             Meaningful Comparison (1-5): 3
                      Thoroughness (1-5): 3
        Impact of Ideas or Results (1-5): 4
                    Recommendation (1-5): 4
               Reviewer Confidence (1-5): 4

Detailed Comments
---------------------------------------------------------------------------
- The mapping between emoji and Plutchik model is interesting.  But I didn't find that the mapping has a strong background. Please consider to add another argument or other references which uses as a backgroud to construct the mapping. 

- "The tweets contained in each set are then the tweets sent by each of the users in the set."  -> The explanation about data splitting is hard to understand. Please rewrite it to make it easier to understand.

- Why use different learning rate between BERTmoticon-LL and BERTmoticon? Please clarify.

- What does it mean by language agnostic way? Please provide further explanation.

- Why BERTmoticon outperform BERTmoticon-LL? I didn't find any analysis and conclusions regarding this result.

- I would suggest to change the figure 5 and 6 into a table to store the keywords. 

- A lot of parts of this paper are really hard to understand because of grammar and structure issues. This work is good, but need a lot of work in rewriting. Without much change, it is difficult to follow the story.
---------------------------------------------------------------------------



============================================================================
                            REVIEWER #2
============================================================================

---------------------------------------------------------------------------
Reviewer's Scores
---------------------------------------------------------------------------
                   Appropriateness (1-5): 5
                           Clarity (1-5): 4
      Originality / Innovativeness (1-5): 3
           Soundness / Correctness (1-5): 4
             Meaningful Comparison (1-5): 3
                      Thoroughness (1-5): 2
        Impact of Ideas or Results (1-5): 3
                    Recommendation (1-5): 2
               Reviewer Confidence (1-5): 5

Detailed Comments
---------------------------------------------------------------------------
This paper presents the results of an experiment with fine-tuning mBERT on a large dataset of tweets labeled with emojis obtained by distant supervision. The emojis are mapped to the basic emotions of Plutchik, and a case study is presented on tweets collected on the topic of the COVID-19 pandemic. 

While the resource and the models are valid, and the experiment is conducted with rigor and explained in details, I feel like several pieces are missing from this paper, giving the impression of a work in progress rather than a mature exposition of experimental results. In no particular order, I will highlight issues I think are relevant:

- the terminology is confusing, having always read "emoticon" as referred to pictograms composed of characters, as opposed to emojis which are characters in their own right by UNICODE standard;

- the absolute prediction performance of both models is very low, extremely low for most emojis and languages;
- the keyword selection for the topical tweets is arbitrary (sinophobia? Should this be so strongly associated with the virus?), and it is not clear how the translation into many languages was done or evaluated;

- a mapping with the basic emotions is presented, but in no way evaluated. Similarly, a comparison with estabilished methods for emotion classification (e.g. the Emolex lexicon) could have been performed;

- since the SemEval 2018 task on emoji prediction was mentioned, results of the proposed model on that benchmark could have been provided.

In summary, this paper shows promising work and developed tools, which however need a stronger scientific framework to be ready for a publication.
---------------------------------------------------------------------------



============================================================================
                            REVIEWER #3
============================================================================

---------------------------------------------------------------------------
Reviewer's Scores
---------------------------------------------------------------------------
                   Appropriateness (1-5): 5
                           Clarity (1-5): 5
      Originality / Innovativeness (1-5): 3
           Soundness / Correctness (1-5): 4
             Meaningful Comparison (1-5): 4
                      Thoroughness (1-5): 4
        Impact of Ideas or Results (1-5): 4
                    Recommendation (1-5): 4
               Reviewer Confidence (1-5): 3

Detailed Comments
---------------------------------------------------------------------------
The paper is about predicting emoticons in multilingual tweets, in particular tweets about Covid 19. The authors fine-tune a multilingual BERT on a dataset of random tweets containing emoticons (80-way classification task). They generate a multilingual Tweet dataset about Covid 19 with a key-word based approach, and predict emoticons for all unlabeled tweets in the dataset. Finally the authors show how the labeled tweets in the Covid-dataset can be used to understand users emotional response to key events in the corona outbreak.

The approaches  for data collection and mbert fine-tuning are not novel, but the main contribution of the paper are the fine-tuned mbert model and the Covid tweet dataset, which will both me made publicly available and can serve subsequent research to do more detailed analysis of tweets related to the corona outbreak.

More detailed comments:

- on p. 2, the authors state: 'we do not consider a subset of tweets about COVID-19, we consider all tweets': Are the authors aware that Twitter only gives a (as far as I  know) 1% sample of all tweets through the API? The sample is allegedly random, but there are no guarantees for this. This is important to keep in mind when drawing conclusions about information spread on Twitter. Also, only geo-located tweets are considered, which as the authors point out is only a small fraction of the available tweets

- wrt to the issue of some languages using smileys with different frequencies: Have the authors thought about under/upsampling data in the training set to alleviate this problem?

- I cannot follow the argument at the end of Section 2 about the LL model being more language agnostic because it doesn't receive information about the input language. Neither does the other model.

- In the intro, the authors state that most tweets about Covid 19 have negative sentiment, but from Figure 7 it looks as if a large amount of tweets (labeled and unlabeled) is joyful

- In the final section (Figure 8), it would be cool to show if there are any interesting findings in the timeline that could not have been made when only looking at the tweets that already contained an emoticon, in order to answer the question why it is helpful to predict emoticons for unlabeled tweets

Typos:
-sec. 3.1: non-English
- end of sec 3: following following

---------------------------------------------------------------------------
Nate's Comments:


-Capitalize the “C” in Claremont Mckenna under Mike’s name
-Footnote 1 should be revealed now for the final version
-The first sentence of the last paragraph in 3.1 maybe could be reworded. I’m not sure that “is due to” 
is the best way to say it. Maybe something like “was constructed by” or “was introduced by”
-Figure 8 description typo – I think you meant to say “mask” not “mast” #
-My only real content related thought is that figure 8 shows a number of world events related to Covid-19; however, they all seem to be focused on the news events that affected the US. Are there any non-US news events that explain any parts of the plot? Since in the paper you stress the importance of not skewing the analysis towards English tweets it feels like you should provide some sort of explanation for this.#
add some international events
